import csv
import json
import numpy as np
import pandas as pd
from typing import Dict, Any, List, Optional
from pathlib import Path


class DataExporter:

    def __init__(self):
        pass

    def export_csv(self, grain_metrics: Dict[int, Dict[str, Any]],
                   filepath: str, include_metadata: bool = True):

        if not grain_metrics:
            raise ValueError("No grain metrics to export")

        # Prepare data for CSV
        rows = []
        headers = set()

        for grain_id, metrics in grain_metrics.items():
            row = {'grain_id': grain_id}

            for key, value in metrics.items():
                if isinstance(value, (int, float, str)):
                    row[key] = value
                    headers.add(key)
                elif isinstance(value, (tuple, list)) and len(value) == 2:
                    # Handle coordinate tuples
                    if 'centroid' in key:
                        row[f'{key}_y'] = value[0]
                        row[f'{key}_x'] = value[1]
                        headers.add(f'{key}_y')
                        headers.add(f'{key}_x')
                elif isinstance(value, np.ndarray):
                    # Skip complex arrays for CSV
                    continue

            rows.append(row)

        # Sort headers for consistent output
        headers = ['grain_id'] + sorted([h for h in headers if h != 'grain_id'])

        # Write CSV
        with open(filepath, 'w', newline='') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=headers)

            if include_metadata:
                # Write metadata as comments
                csvfile.write(f"# Grain Analysis Results\n")
                csvfile.write(f"# Total grains: {len(grain_metrics)}\n")
                csvfile.write(f"# Generated by GrainStat\n")
                csvfile.write(f"#\n")

            writer.writeheader()

            for row in rows:
                # Fill missing values
                complete_row = {header: row.get(header, '') for header in headers}
                writer.writerow(complete_row)

    def export_excel(self, grain_metrics: Dict[int, Dict[str, Any]],
                     statistics: Dict[str, Any], filepath: str):

        # Create pandas dataframe from grain metrics
        df_grains = self._create_grains_dataframe(grain_metrics)

        # Create statistics dataframe
        df_stats = self._create_statistics_dataframe(statistics)

        # Write to Excel with multiple sheets
        with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
            df_grains.to_excel(writer, sheet_name='Grain_Data', index=False)
            df_stats.to_excel(writer, sheet_name='Statistics', index=False)

            # Add metadata sheet
            metadata = {
                'Parameter': ['Total Grains', 'Analysis Date', 'Software'],
                'Value': [len(grain_metrics), pd.Timestamp.now(), 'GrainStat v1.0']
            }
            pd.DataFrame(metadata).to_excel(writer, sheet_name='Metadata', index=False)

    def export_json(self, grain_metrics: Dict[int, Dict[str, Any]],
                    statistics: Dict[str, Any], filepath: str):

        # Convert numpy arrays and other non-JSON serializable objects
        exportable_metrics = {}

        for grain_id, metrics in grain_metrics.items():
            exportable_metrics[str(grain_id)] = self._make_json_serializable(metrics)

        exportable_stats = self._make_json_serializable(statistics)

        data = {
            'metadata': {
                'software': 'GrainStat',
                'version': '1.0.0',
                'analysis_date': pd.Timestamp.now().isoformat(),
                'grain_count': len(grain_metrics)
            },
            'grain_metrics': exportable_metrics,
            'statistics': exportable_stats
        }

        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2)

    def export_summary_csv(self, statistics: Dict[str, Any], filepath: str):
        # Export just the summary statistics
        rows = []

        def flatten_dict(d, prefix=''):
            for key, value in d.items():
                new_key = f"{prefix}_{key}" if prefix else key

                if isinstance(value, dict):
                    rows.extend(flatten_dict(value, new_key))
                elif isinstance(value, (int, float, str)):
                    rows.append({'parameter': new_key, 'value': value})

        flatten_dict(statistics)

        with open(filepath, 'w', newline='') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=['parameter', 'value'])
            writer.writeheader()
            writer.writerows(rows)

    def export_grain_boundaries(self, grain_metrics: Dict[int, Dict[str, Any]],
                                labeled_image: np.ndarray, filepath: str):
        # Export grain boundary coordinates
        from skimage import morphology

        boundaries = {}

        for grain_id in grain_metrics.keys():
            grain_mask = labeled_image == grain_id
            boundary = grain_mask ^ morphology.erosion(grain_mask)
            boundary_coords = np.where(boundary)

            boundaries[str(grain_id)] = {
                'x_coords': boundary_coords[1].tolist(),
                'y_coords': boundary_coords[0].tolist()
            }

        with open(filepath, 'w') as f:
            json.dump(boundaries, f, indent=2)

    def _create_grains_dataframe(self, grain_metrics: Dict[int, Dict[str, Any]]) -> pd.DataFrame:
        # Convert grain metrics to pandas DataFrame
        data = []

        for grain_id, metrics in grain_metrics.items():
            row = {'grain_id': grain_id}

            for key, value in metrics.items():
                if isinstance(value, (int, float, str)):
                    row[key] = value
                elif isinstance(value, (tuple, list)) and len(value) == 2:
                    if 'centroid' in key:
                        row[f'{key}_y'] = value[0]
                        row[f'{key}_x'] = value[1]
                elif isinstance(value, np.ndarray):
                    # Skip arrays for DataFrame
                    continue

            data.append(row)

        return pd.DataFrame(data)

    def _create_statistics_dataframe(self, statistics: Dict[str, Any]) -> pd.DataFrame:
        # Flatten statistics dictionary for DataFrame
        flattened = []

        def flatten_stats(d, prefix=''):
            for key, value in d.items():
                new_key = f"{prefix}.{key}" if prefix else key

                if isinstance(value, dict):
                    flatten_stats(value, new_key)
                elif isinstance(value, (int, float, str)):
                    flattened.append({'parameter': new_key, 'value': value})

        flatten_stats(statistics)
        return pd.DataFrame(flattened)

    def _make_json_serializable(self, obj):
        # Convert objects to JSON-serializable format
        if isinstance(obj, dict):
            return {key: self._make_json_serializable(value) for key, value in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [self._make_json_serializable(item) for item in obj]
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, (np.integer, np.floating)):
            return obj.item()
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif pd.isna(obj) or obj is None:
            return None
        elif isinstance(obj, (int, float, str, bool)):
            return obj
        else:
            return str(obj)  # Convert everything else to string

    def export_batch_summary(self, batch_results: List[Dict[str, Any]],
                             filepath: str):
        # Export summary of multiple analyses
        summary_data = []

        for i, result in enumerate(batch_results):
            statistics = result.get('statistics', {})

            row = {
                'analysis_id': i + 1,
                'grain_count': statistics.get('grain_count', 0),
            }

            # Add ECD statistics
            if 'ecd_statistics' in statistics:
                ecd_stats = statistics['ecd_statistics']
                row.update({
                    'mean_ecd_um': ecd_stats.get('mean', 0),
                    'median_ecd_um': ecd_stats.get('median', 0),
                    'std_ecd_um': ecd_stats.get('std', 0),
                    'min_ecd_um': ecd_stats.get('min', 0),
                    'max_ecd_um': ecd_stats.get('max', 0)
                })

            # Add ASTM grain size
            if 'astm_grain_size' in statistics:
                astm = statistics['astm_grain_size']
                row['astm_grain_size_number'] = astm.get('grain_size_number', None)

            summary_data.append(row)

        df = pd.DataFrame(summary_data)
        df.to_csv(filepath, index=False)

    def export_correlation_matrix(self, grain_metrics: Dict[int, Dict[str, Any]],
                                  filepath: str, metrics: Optional[List[str]] = None):
        # Export correlation matrix of grain metrics
        if metrics is None:
            metrics = ['ecd_um', 'area_um2', 'aspect_ratio', 'shape_factor',
                       'perimeter_um', 'eccentricity', 'solidity']

        # Extract data for correlation
        data = {}
        for metric in metrics:
            values = []
            for grain in grain_metrics.values():
                if metric in grain and np.isfinite(grain[metric]):
                    values.append(grain[metric])

            if values:
                data[metric] = values

        # Create DataFrame and calculate correlation
        df = pd.DataFrame(data)
        correlation_matrix = df.corr()

        # Export to CSV
        correlation_matrix.to_csv(filepath)

        return correlation_matrix